# -*- coding: utf-8 -*-
"""5_Laptop Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TdBtYpYbTqxzbeV1TrTQkbTVCva4D9Rc
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/drive/MyDrive/7_CSV FILE/laptop_price.csv",encoding='latin')
df

# Drop columns
df.drop(columns=['laptop_ID'],inplace=True)

# Check missing values
print(df.isnull().sum())

# Cheack duplicated values
print(df.duplicated().sum())
print()
print("-"*40)
df[df.duplicated()]

# drop duplicaes values
df.drop_duplicates(inplace=True)

df.info()

df.sample(5)

df['Price']=round(df['Price_euros']*130.44,2).astype('int')

df.drop(columns=['Price_euros'],inplace=True)

sns.histplot(df['Price'],kde=True)

sns.kdeplot(df['Price'])

# Right skewed data

sns.kdeplot(np.log(df['Price']))

# converts price to its natural lograrithm (lm)
np.exp(np.log(df['Price']))

#sorted in descending order by default.
print(df['Company'].value_counts())

df['Company'].value_counts().plot(kind='bar')

len(df['Company'].value_counts())

# Company ascending order
print(df.groupby('Company')['Company'].count().sort_values(ascending=False))

# Result: For every row, you get the total number of times that
#particular company appears in the entire DataFrame.

df.groupby('Company')['Company'].transform('count')

df['Company']

df = df[df.groupby('Company')['Company'].transform('count')>20]

df.reset_index(drop=True,inplace=True)

df

print(df['Company'].value_counts())

df['Company'].value_counts().plot(kind='bar')

df.groupby('Company')['Price'].mean().sort_values(ascending=False)

sorted_company_list = df.groupby('Company')['Price'].mean().sort_values(ascending=False).index
sorted_company_list

sorted_company_list[::-1]

sns.color_palette("Reds")

sns.barplot(x=df['Company'],y=df['Price'],errorbar=None,order=sorted_company_list,
            hue=df['Company'],palette='Reds',hue_order=sorted_company_list[::-1])

df.sample()

print(df['Product'].value_counts())

df.drop(columns=['Product'],inplace=True)

print(df['TypeName'].value_counts())

df.sample()

df['TypeName'].value_counts().plot(kind='bar')

df.groupby('TypeName')['Price'].mean().sort_values(ascending=False)

sorted_typelist=df.groupby('TypeName')['Price'].mean().sort_values(ascending=False).index
sorted_typelist

sns.barplot(x=df['TypeName'],y=df['Price'],errorbar=None,order=sorted_typelist,
            palette="Reds",hue=df['TypeName'],hue_order=sorted_typelist[::-1])
plt.xticks(rotation=90)
plt.show()

df.sample()

print(df['Inches'].value_counts())

sns.histplot(df['Inches'],kde=True)

sns.scatterplot(x=df['Inches'],y=df['Price'],color='r')

print(df['ScreenResolution'].value_counts())

a="Ips Panel Full HD / Touchscreen 1920x1080"
a.split()[-1].split('x')[0]

(lambda a:a.split()[-1].split('x')[0])("IPS Panel Full HD / Touchscreen 1920x1080")

df['X_res']=df['ScreenResolution'].apply(lambda a:a.split()[-1].split('x')[0]).astype('int')
df['Y_res']=df['ScreenResolution'].apply(lambda a:a.split()[-1].split('x')[1]).astype('int')
df['Touchscreen']=df['ScreenResolution'].apply(lambda a:1 if "Touchscreen" in a else 0)
df['Ips']=df['ScreenResolution'].apply(lambda a:1 if "IPS" in a else 0)

df.sample(5)

df.drop(columns=['ScreenResolution'],inplace=True)

df.sample()

df['Touchscreen'].value_counts().plot(kind='bar')

sns.barplot(x=df["Touchscreen"],y=df['Price'])

df["Ips"].value_counts().plot(kind='bar')

sns.barplot(x=df['Ips'],y=df['Price'],errorbar=None)

print(df['Cpu'].value_counts())

df['Cpu_Speed']=df['Cpu'].apply(lambda x:x.split()[-1].replace('GHz',"")).astype('float')

df.sample(5)

df['Cpu']=df['Cpu'].apply(lambda x:" ".join(x.split()[0:3]))

print(df['Cpu'].value_counts())

def fetch_processor_name(proc):
    if proc.split()[0]=='Intel':
        if proc.split()[1]=='Core':
            return proc
        else:
            return " ".join(proc.split()[0:2])
    else:
        if proc[4]=='E':
            return "AMD E-Series"
        elif proc[4]=='R':
            return "AMD Ryzen Series"
        elif proc[4]=='A':
            return "AMD A Series"
        else:
            return "AMD Fx series"

df['Cpu']=df["Cpu"].apply(fetch_processor_name)

print(df['Cpu'].value_counts())

df['Cpu'].value_counts().plot(kind='bar')

sorted_cpulist= df.groupby('Cpu')['Price'].mean().sort_values(ascending=False).index
sorted_cpulist

sns.barplot(x=df['Cpu'],y=df['Price'],errorbar=None,order=sorted_cpulist,
            palette='Reds',hue=df['Cpu'],hue_order=sorted_cpulist[::-1])
plt.xticks(rotation=90)
plt.show()

df['Ram'] = df['Ram'].apply(lambda x:x.replace("GB","")).astype('int')
df['Weight'] = df['Weight'].apply(lambda x:x.replace("kg","")).astype("float")

df['Ram'].value_counts().plot(kind='bar', color= 'orange')

sns.barplot(x=df['Ram'],y=df['Price'],errorbar=None,hue=df['Ram'],palette="Reds")

print(df['Gpu'].value_counts())

df['Gpu']=df['Gpu'].apply(lambda x:" ".join(x.split()[0:2]))

print(df['Gpu'].value_counts())

def fetch_gpu_name(text):
    if text.split()[0]=='AMD':
        return "AMD GPU"
    elif text == "Intel Graphics":
        return "Intel HD"
    elif text == "Nvidia GTX":
        return "Nvidia GeForce"
    else:
        return text

df["Gpu"] = df["Gpu"].apply(fetch_gpu_name)

print(df['Gpu'].value_counts())

df['Gpu'].value_counts().plot(kind='bar', color='orange')

sorted_gpulist = df.groupby('Gpu')['Price'].mean().sort_values(ascending=False).index
sorted_gpulist

sns.barplot(x=df['Gpu'],y=df['Price'],errorbar=None,order=sorted_gpulist,
            palette='Reds',hue=df['Gpu'],hue_order=sorted_gpulist[::-1])
plt.xticks(rotation=90)
plt.show()

df.sample()

print(df['OpSys'].value_counts())

def fetch_os_name(os):
    if os=="Windows 10 S":
        return "Windows 10"
    elif os=="macOS" or os=="Mac OS X":
        return "MacOS"
    elif os=="Android" or os=="Chrome OS" or os=="Linux":
        return "Linux/Chrome OS/Others"
    else:
        return os

df['OpSys']=df['OpSys'].apply(fetch_os_name)

print(df['OpSys'].value_counts())

sorted_oslist = df.groupby('OpSys')['Price'].mean().sort_values(ascending=False).index
sorted_oslist

sns.barplot(x=df['OpSys'],y=df['Price'],errorbar=None,order=sorted_oslist,
            palette="Reds",hue=df['OpSys'],hue_order=sorted_oslist[::-1])
plt.xticks(rotation=90)
plt.show()

print(df['Memory'].value_counts())

a = "512GB SSD + 1.0TB Hybrid"
a.replace(r"\.0","")

# SSD
# HDD
# SSD + HDD
# Flash Storage
# Hybrid
# SSD + SSD
# Flash Storage + SSD
# HDD + HDD
# SSD + Hybrid

# SSD   HDD     Flash Storage       Hybrid
# Regex (regular expression)

df['Memory']=df['Memory'].astype(str).replace(r"\.0","",regex=True)

print(df['Memory'].value_counts())

df['Memory']=df['Memory'].str.replace("GB","")
df['Memory']=df['Memory'].str.replace("TB","000")

print(df['Memory'].value_counts())

new = df['Memory'].str.split('+',expand=True)
df['first']=new[0]
df['first']=df['first'].str.strip()
df['second']=new[1]

df.sample(3)

df['Layer1HDD']=df['first'].astype(str).apply(lambda x:1 if "HDD" in x else 0)
df['Layer1SSD']=df['first'].astype(str).apply(lambda x:1 if "SSD" in x else 0)
df['Layer1Hybrid']=df['first'].astype(str).apply(lambda x:1 if "Hybrid" in x else 0)
df['Layer1Flash_storage']=df['first'].astype(str).apply(lambda x:1 if "Flash" in x else 0)

df.sample()

df['first']=df['first'].str.replace(r"\D","",regex=True)
# \D : any character which is not digit
# \d : any character which is a digit

df.sample()

df['second'].fillna("0",inplace=True)
df['second']=df['second'].str.strip()
df['Layer2HDD']=df['second'].apply(lambda x:1 if "HDD" in x else 0)
df['Layer2SSD']=df['second'].apply(lambda x:1 if "SSD" in x else 0)
df['Layer2Hybrid']=df['second'].apply(lambda x:1 if "Hybrid" in x else 0)
df['Layer2Flash_Storage']=df['second'].apply(lambda x:1 if "Flash" in x else 0)
df['second']=df['second'].str.replace(r"\D","",regex=True)

df.sample()

df['first']=df['first'].astype('int')
df['second']=df['second'].astype('int')

df['HDD']=df['first']*df['Layer1HDD']+df['second']*df['Layer2HDD']
df['SSD']=df['first']*df['Layer1SSD']+df['second']*df['Layer2SSD']
df['Hybrid']=df['first']*df['Layer1Hybrid']+df['second']*df['Layer2Hybrid']
df['Flash_Storage']=df['first']*df['Layer1Flash_storage']+df['second']*df['Layer2Flash_Storage']

df.columns

df.drop(columns=['first',
       'second', 'Layer1HDD', 'Layer1SSD', 'Layer1Hybrid',
       'Layer1Flash_storage', 'Layer2HDD', 'Layer2SSD', 'Layer2Hybrid',
       'Layer2Flash_Storage'],inplace=True)

df.columns

df.sample(10)

df.drop(columns=['Memory'],inplace=True)

df.info()

df.corr(numeric_only=True)

sns.heatmap(df.corr(numeric_only=True),cmap='summer')

df.corr(numeric_only=True)['Price']

df.drop(columns=['Hybrid','Flash_Storage'],inplace=True)

# screen size       : Inches
# screen resolution : X_res, Y_res
# resolution: number of pixels on the screen
# pixel density

df['PPi']=round((df['X_res']**2+df['Y_res']**2)*0.5/df['Inches'],2)

df.corr(numeric_only=True)['Price']

df.drop(columns=['X_res','Y_res','Inches'],inplace=True)

sns.boxplot(x=df['Price'], color='orange')

sns.kdeplot(df[df['Price']<280000]['Price'])

X=df.drop(columns=['Price'])
y=df['Price']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=42)

X.shape,X_train.shape,X_test.shape

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from xgboost import XGBRegressor

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error

# - Encoding : process of converting text data to numerical data
# -  Label Encoding (output Labels)
#    - LabelEncoder
# - Feature Encoding(input features)
#     - Oridinal Encoding : Very Good(2), Poor(0), Excellent(3), Satisfactory(1)
#         - OridinalEncoder
#     - Nominal Enciding : Man/Woman, Apple/Acer/Dell/Hp
#         - OneHotEncoder

# Company     Company_HP  Company_Ap
# Apple            0           1
# Apple            0           1
# HP               1           0
# Apple            0           1
# Dell             0           0
# HP               1           0
# Dell             0           0
# Apple            0           1

X_train.sample()

# Linear Regression
ct_ohe= ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model= LinearRegression()
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Regularization Technique
    #  - Lasso()
    #  - Ridge()

X_train.sample()

# y=mx+c
# y=m1x1+m2x2+m3x3+... +c
# price=b1.RAM +b2.weight+b3.cpu+b4.cpu_speed+.....+b0

# query=np.array([["Dell","Notebook","Intel Core i5",16,"Intel HD","Windows 10",2.0,0,0,2.2,0,512,141.2]])
# pipe.predict(query)

# Multi-collinearity
# Overfitting

# Ridge Regression : L2 Regularization : penalty : square of coefficient
ct_ohe = ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model =LinearRegression()
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score",r2_score(y_test,y_pred))
print("MAE",mean_absolute_error(y_test,y_pred))
print("RMSE",root_mean_squared_error(y_test,y_pred))

# Lasso Regression : L1 regularization : panalty : absolute value of cofficients
# internal automatic feature selection

# Whwn is Lasso useful ?
    #  - When you have many features, and you think not all are useful.
    #  - you suspect some features are not important
    #  - you wnat a simpler model

# Lasso is very sensitive to feature scaling
# if your feature are on very diffrent scales, it is good idea to normalize or standarslize them
# we will standardize numeric features using standardscaler.

# Lasso Regression
categorical_feature=[0,1,2,4,5]
numerical_features = [3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_feature),
    ('num',StandardScaler(),numerical_features)
])
reg_model= Lasso(alpha=0.01,max_iter=100000)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Decision Tree Regression
ct_ohe = ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model =DecisionTreeRegressor(max_depth=11)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# KNN(KNeighborrsRegressor)

# K Neighbors Regression
ct_ohe = ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model =KNeighborsRegressor(n_neighbors=10)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Adabost Regression
ct_ohe = ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(drop='first'),[0,1,2,4,5])],remainder='passthrough')
reg_model =AdaBoostRegressor(n_estimators=100,random_state=42,learning_rate=0.1)
pipe=Pipeline([('s1',ct_ohe),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Ensemble : combination of multiple algorithms
# Crowd always known best answer

# Homogenous ensemble : algorithms for all models in esemble are in same
# Heterogenous ensemble : algorithms are diffrents

# Type of Ensemble Models
    # Voting
    # Stacking
    # Bagging : Bootstrap + Aggregation (Homogenous ensemble)
        # Random Forest : base estimator is always Decision Tree
    # Boosting

# AddaBoost
# Adaoative Boosting

# Random Forest
#   2 sources of randomness
#       - Bootstrap sampling
#       - Random Feature Selection

# RandomForest Regression
categorical_features =[0,1,2,4,5]
numerical_features  = [3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_feature),
    ('num',StandardScaler(),numerical_features)
])
reg_model =RandomForestRegressor(random_state=30,n_estimators=500,max_depth=12)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# Gradient Boosting
    # Gradient Descent

# XGB Regression
categorical_features =[0,1,2,4,5]
numerical_features  = [3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_feature),
    ('num',StandardScaler(),numerical_features)
])
reg_model = XGBRegressor(random_state=15,n_estimators=950, learning_rate=0.1,
                         max_depth=2, reg_lambda=1, reg_alpha=0.5,subsample=0.8)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

# GridSearch CV
from sklearn.model_selection import GridSearchCV

# # GradientBoosting Regression
# categorical_features=[0,1,2,4,5]
# numerical_features=[3,6,7,8,9,10,11,12]
# preprocessor= ColumnTransformer(transformers=[
#     ('cat',OneHotEncoder(drop='first'),categorical_features),
#     ('num',StandardScaler(),numerical_features)
#     ])
# reg_model= GradientBoostingRegressor(random_state=15)
# pipe=Pipeline([('s1',preprocessor),('regressor',reg_model)])
# param_grid={
#     'regressor__n_estimators':[100,200,500,1000],
#     'regressor__learning_rate':[0.05,0.1,0.2],
#     'regressor__max_depth':[3,4,5,8,10,12],
#     'regressor__subsample':[0.8,1.0]

# }
# grid_search=GridSearchCV(pipe,param_grid,cv=3,scoring='r2',verbose=1,n_jobs=-1)
# grid_search.fit(X_train,y_train)
# best_model=grid_search.best_estimator_
# y_pred=best_model.predict(X_test)
# print("R2 score:",r2_score(y_test,y_pred))
# print("MAE:",mean_absolute_error(y_test,y_pred))
# print("RMSE:",root_mean_squared_error(y_test,y_pred))

# GradientBoosting Regression
categorical_features=[0,1,2,4,5]
numerical_features=[3,6,7,8,9,10,11,12]
preprocessor= ColumnTransformer(transformers=[
    ('cat',OneHotEncoder(drop='first'),categorical_features),
    ('num',StandardScaler(),numerical_features)
    ])
reg_model= GradientBoostingRegressor(random_state=15,n_estimators=950, learning_rate=0.1,max_depth=2)
pipe=Pipeline([('s1',preprocessor),('s2',reg_model)])

pipe.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
print("R2 score:",r2_score(y_test,y_pred))
print("MAE:",mean_absolute_error(y_test,y_pred))
print("RMSE:",root_mean_squared_error(y_test,y_pred))

X_train.sample()

query=[['HP','Ultrabook','Intel Core i5',16,'Intel HD','Windows 10',2.2,0,0,2.0,0,512,144]]

op=pipe.predict(query)

op

print("The estimated price of the laptop with the above metioned space is  ₹"+str(int(round(op[0],-2)))+"." )

# Deployment

# Streamlit
# Strimlit cloud
# Github

import pickle
pickle.dump(pipe,open('pipe.pkl','wb'))
pickle.dump(df,open('df.pkl','wb'))

!pip install Streamlit --quiet

# Commented out IPython magic to ensure Python compatibility.
# %%writefile laptop_app.py
# import streamlit as st
# # import pickle
# # df=pickle.load(open('df.pkl','rb'))
# # pipe=pickle.load(open('pipe.pkl','rb'))
# import joblib
# pipe=joblib.load('pipe_compressed')
# df-joblib.load('df')
# st.title("Laptop Price Predictor App")
# st.text("This app is using only a select few laptops(around 1200 laptops), so it may not align exactly with real world data")
# 
# company=st.selectbox("Manufacturer of the Laptop",df['Company'].unique(),index=4)
# typename=st.radio("Type of the Laptop",df['TypeName'].unique(),horizontal=True,index=1)
# cpu=st.selectbox("Processor",df['Cpu'].unique())
# ram=st.pills("RAM on the system(in GB)",[4,8,12,16,24,32,64,128])
# gpu=st.radio("Graphics Card",df['Gpu'].unique(),index=1,horizontal=True)
# os=st.selectbox("Operating System",df['OpSys'].unique(),index=2)
# weight=st.slider("Weight of the laptop(in kg)",min_value=0.7,max_value=4.8,step=0.1,value=2.1)
# touchscreen=st.pills("Does the laptop have touchscreen?",['Yes','No'])
# ips=st.pills("Does the laptop have an IPS display?",['Yes','No'])
# cpu_speed=st.slider("Clock Speed of CPU(in GHz)",min_value=0.9,max_value=3.6,step=0.1,value=2.3)
# hdd=st.pills("Hard disk size on the system(in GB). If only SSD is present, select this is as 0",
#              [0,512,1024,2000])
# ssd=st.pills("SSD storage on the system(in GB).",[0,256,512,1024,2000])
# screen_size=st.slider("Screen size(measured diagonally, in inches)",min_value=10.0,max_value=18.4,value=15.6,step=0.1)
# screen_resolution=st.selectbox("Laptop Screen Resolution (in pixels)",
#  ["2560x1600","1440x900","1920x1080","2880x1800","1366x768","2304x1440","3200x1800","1920x1200","2256x1504",
#   "3840x2160","2160x1440","2560x1440","1600x900","2736x1824","2400x1600"],index=2)
# 
# if st.button("PREDICT PRICE"):
#     if touchscreen == 'Yes':
#         touchscreen=1
#     else:
#         touchscreen=0
#     if ips == 'Yes':
#         ips=1
#     else:
#         ips=0
#     X_res=int(screen_resolution.split('x')[0])
#     Y_res=int(screen_resolution.split('x')[1])
#     ppi = ((X_res**2)+(Y_res**2))**0.5/screen_size
#     query=[[company,typename,cpu,ram,gpu,os,weight,touchscreen,ips,cpu_speed,hdd,ssd,ppi]]
#     op=pipe.predict(query)
#     st.subheader("The estimated price of the laptop with the above mentioned specs is ₹"+str(int(round(op[0],-2)))+".")

df.sample()

df['Cpu_Speed'].describe()

!streamlit run laptop_app.py & npx localtunnel --port 8501

import sklearn
sklearn.__version__

import joblib

pipe

pipe.steps

joblib.dump(pipe,'pipe_compressed',compress=3)

model_reg=joblib.load('pipe_compressed')

joblib.dump(df,'df')

model_reg.steps

